<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <div class="ch bg fy fz ga gb"><div><h1 id="22ef" class="pw-post-title gr gs gt be gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq hr hs ht bj" data-testid="storyTitle" data-selectable-paragraph="">Machine Learning — Text Processing</h1><div><div class="speechify-ignore ab co"><div class="speechify-ignore bg l"><div class="hu hv hw hx hy ab"><div><div class="ab hz"><a href="https://medium.com/@javaid.nabi?source=post_page-----1d5a2d638958--------------------------------" rel="noopener follow"><div><div class="bl" aria-hidden="false" aria-describedby="1" aria-labelledby="1"><div class="l ia ib bx ic id"><div class="l fi"><img alt="Javaid Nabi" class="l fc bx dc dd cw" src="https://miro.medium.com/v2/resize:fill:88:88/1*X5vPFhNx6Ah8dXYYuL4N5Q.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"><div class="ie bx l dc dd fr n if fs"></div></div></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----1d5a2d638958--------------------------------" rel="noopener follow"><div class="ig ab fi"><div><div class="bl" aria-hidden="false" aria-describedby="2" aria-labelledby="2"><div class="l ih ii bx ic ij"><div class="l fi"><img alt="Towards Data Science" class="l fc bx bq ik cw" src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="24" height="24" loading="lazy" data-testid="publicationPhoto"><div class="ie bx l bq ik fr n if fs"></div></div></div></div></div></div></a></div></div><div class="bm bg l"><div class="ab"><div style="flex:1"><span class="be b bf z bj"><div class="il ab q"><div class="ab q im"><div class="ab q"><div><div class="bl" aria-hidden="false" aria-describedby="3" aria-labelledby="3"><p class="be b in io bj"><a class="af ag ah ai aj ak al am an ao ap aq ar ip" data-testid="authorName" href="https://medium.com/@javaid.nabi?source=post_page-----1d5a2d638958--------------------------------" rel="noopener follow">Javaid Nabi</a></p></div></div></div><span class="iq ir" aria-hidden="true"><span class="be b bf z dt">·</span></span><p class="be b in io dt"><span><a class="is it ah ai aj ak al am an ao ap aq ar ew iu iv" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F70c04bf6660e&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-text-processing-1d5a2d638958&amp;user=Javaid+Nabi&amp;userId=70c04bf6660e&amp;source=post_page-70c04bf6660e----1d5a2d638958---------------------post_header-----------" rel="noopener follow">Follow</a></span></p></div></div></span></div></div><div class="l iw"><span class="be b bf z dt"><div class="ab cm ix iy iz"><div class="ja jb ab"><div class="be b bf z dt ab jc"><span class="jd l iw">Published in</span><div><div class="l" aria-hidden="false" aria-describedby="4" aria-labelledby="4"><a class="af ag ah ai aj ak al am an ao ap aq ar ip ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page-----1d5a2d638958--------------------------------" rel="noopener follow"><p class="be b bf z je jf jg jh ji jj jk jl bj">Towards Data Science</p></a></div></div></div><div class="h k"><span class="iq ir" aria-hidden="true"><span class="be b bf z dt">·</span></span></div></div><span class="be b bf z dt"><div class="ab ae"><span data-testid="storyReadTime">10 min read</span><div class="jm jn l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="be b bf z dt">·</span></span></div><span data-testid="storyPublishDate">Sep 13, 2018</span></div></span></div></span></div></div></div><div class="ab co jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd"><div class="h k w ff fg q"><div class="kt l"><div class="ab q ku kv"><div class="pw-multi-vote-icon fi jd kw kx ky"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1d5a2d638958&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-text-processing-1d5a2d638958&amp;user=Javaid+Nabi&amp;userId=70c04bf6660e&amp;source=-----1d5a2d638958---------------------clap_footer-----------" rel="noopener follow"><div><div class="bl" aria-hidden="false" aria-describedby="5" aria-labelledby="5"><div class="kz ao la lb lc ld am le lf lg ky"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lh li lj lk ll lm ln"><div><div class="bl" aria-hidden="false" aria-describedby="78" aria-labelledby="78"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xs lw">1.5K<span class="l h g f sk sl"></span></button></p></div></div></div></div></div><div><div class="bl" aria-hidden="false" aria-describedby="6" aria-labelledby="6"><button class="ao kz lr ls ab q fj lt lu" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="lq"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg><p class="be b du z dt"><span class="pw-responses-count lp lq">9</span></p></button></div></div></div><div class="ab q ke kf kg kh ki kj kk kl km kn ko kp kq kr ks"><div class="lv k j i d"></div><div class="h k"><div><div class="bl" aria-hidden="false" aria-describedby="7" aria-labelledby="7"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1d5a2d638958&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-text-processing-1d5a2d638958&amp;source=-----1d5a2d638958---------------------bookmark_footer-----------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dt lw" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="fc lx cm"><div class="l ae"><div class="ab ca"><div class="ly lz ma mb mc md ch bg"><div class="ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3D1d5a2d638958&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmachine-learning-text-processing-1d5a2d638958&amp;source=-----1d5a2d638958---------------------post_audio_button-----------" rel="noopener follow"><div><div class="bl" aria-hidden="false" aria-describedby="26" aria-labelledby="26"><button aria-label="Listen" data-testid="audioPlayButton" class="af fj ah ai aj ak al me an ao ap ew mf mg lu mh mi mj mk ml s mm mn mo mp mq mr ms u mt mu mv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"></path></svg><div class="j i d"><p class="be b bf z dt">Listen</p></div></button></div></div></a></span></div></div></div></div></div><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false" aria-describedby="9" aria-labelledby="9"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af fj ah ai aj ak al me an ao ap ew mf mg lu mh mi mj mk ml s mm mn mo mp mq mr ms u mt mu mv"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg><div class="j i d"><p class="be b bf z dt">Share</p></div></button></div></div></div></div></div></div></div></div></div><p id="36fc" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Text Processing is one of the most common task in many ML applications. Below are some examples of such applications.</p><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="3e41" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph="">• <strong class="oa gu">Language Translation: Translation of a sentence from one language to another.</strong></span><span id="97a1" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph="">• <strong class="oa gu">Sentiment Analysis: To determine, from a text corpus, whether the  sentiment towards any topic or product etc. is positive, negative, or neutral.</strong></span><span id="fd1e" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph="">• <strong class="oa gu">Spam Filtering:  Detect unsolicited and unwanted email/messages.</strong></span></pre><figure class="nu nv nw nx ny on ok ol paragraph-image"><div role="button" tabindex="0" class="oo op fi oq bg or"><div class="ok ol om"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*KljmJybQDj1mJAL-oS8VWQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*KljmJybQDj1mJAL-oS8VWQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*KljmJybQDj1mJAL-oS8VWQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*KljmJybQDj1mJAL-oS8VWQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*KljmJybQDj1mJAL-oS8VWQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*KljmJybQDj1mJAL-oS8VWQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KljmJybQDj1mJAL-oS8VWQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*KljmJybQDj1mJAL-oS8VWQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*KljmJybQDj1mJAL-oS8VWQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*KljmJybQDj1mJAL-oS8VWQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*KljmJybQDj1mJAL-oS8VWQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*KljmJybQDj1mJAL-oS8VWQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*KljmJybQDj1mJAL-oS8VWQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*KljmJybQDj1mJAL-oS8VWQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg md os c" width="700" height="325" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:1050/1*KljmJybQDj1mJAL-oS8VWQ.png"></picture></div></div><figcaption class="ot fe ou ok ol ov ow be b bf z dt" data-selectable-paragraph="">Courtesy (<a class="af ox" href="https://sigmoidal.io/machine-learning-terminology-explained-top-8-must-know-concepts/" rel="noopener ugc nofollow" target="_blank">sigmoidal</a>)</figcaption></figure><p id="647b" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">These applications deal with huge amount of text to perform classification or translation and involves a lot of work on the back end. Transforming text into something an algorithm can digest is a complicated process. In this article, we will discuss the steps involved in text processing.</p><h2 id="a413" class="oe of gt be oy oz pa dx pb pc pd dz pe nh pf pg ph nl pi pj pk np pl pm pn po bj" data-selectable-paragraph="">Step 1 : Data Preprocessing</h2><ul class=""><li id="5392" class="mw mx gt my b mz pp nb nc nd pq nf ng nh pr nj nk nl ps nn no np pt nr ns nt pu pv pw bj" data-selectable-paragraph="">Tokenization — convert sentences to words</li><li id="e5ed" class="mw mx gt my b mz px nb nc nd py nf ng nh pz nj nk nl qa nn no np qb nr ns nt pu pv pw bj" data-selectable-paragraph="">Removing unnecessary punctuation, tags</li><li id="cc93" class="mw mx gt my b mz px nb nc nd py nf ng nh pz nj nk nl qa nn no np qb nr ns nt pu pv pw bj" data-selectable-paragraph="">Removing stop words — frequent words such as ”the”, ”is”, etc. that do not have specific semantic</li><li id="3e7e" class="mw mx gt my b mz px nb nc nd py nf ng nh pz nj nk nl qa nn no np qb nr ns nt pu pv pw bj" data-selectable-paragraph="">Stemming — words are reduced to a root by removing inflection through dropping unnecessary characters, usually a suffix.</li><li id="1295" class="mw mx gt my b mz px nb nc nd py nf ng nh pz nj nk nl qa nn no np qb nr ns nt pu pv pw bj" data-selectable-paragraph="">Lemmatization — Another approach to remove inflection by determining the part of speech and utilizing detailed database of the language.</li></ul><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="857d" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph="">The stemmed form of studies is: studi<br>The stemmed form of studying is: study</span><span id="8c88" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph="">The lemmatized form of studies is: study<br>The lemmatized form of studying is: study</span></pre><p id="fb1f" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Thus stemming &amp; lemmatization help reduce words like ‘studies’, ‘studying’ to a common base form or root word ‘study’. For detailed discussion on Stemming &amp; Lemmatization refer <a class="af ox" href="https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/" rel="noopener ugc nofollow" target="_blank">here </a>. Note that not all the steps are mandatory and is based on the application use case. For Spam Filtering we may follow all the above steps but may not for language translation problem.</p><p id="abdc" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">We can use python to do many text preprocessing operations.</p><ul class=""><li id="075c" class="mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt pu pv pw bj" data-selectable-paragraph=""><a class="af ox" href="http://www.nltk.org/" rel="noopener ugc nofollow" target="_blank">NLTK</a> — The Natural Language ToolKit is one of the best-known and most-used NLP libraries, useful for all sorts of tasks from t tokenization, stemming, tagging, parsing, and beyond</li><li id="b52d" class="mw mx gt my b mz px nb nc nd py nf ng nh pz nj nk nl qa nn no np qb nr ns nt pu pv pw bj" data-selectable-paragraph=""><a class="af ox" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">BeautifulSoup</a> — Library for extracting data from HTML and XML documents</li></ul><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="2c93" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph="">#using NLTK library, we can do lot of text preprocesing<br><strong class="oa gu">import nltk<br>from nltk.tokenize import word_tokenize</strong><br>#function to split text into word<br><strong class="oa gu">tokens = word_tokenize("The quick brown fox jumps over the lazy dog")<br>nltk.download('stopwords')<br>print(tokens)</strong></span></pre><p id="bce2" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">OUT: [‘The’, ‘quick’, ‘brown’, ‘fox’, ‘jumps’, ‘over’, ‘the’, ‘lazy’, ‘dog’]</p><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="9116" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">from nltk.corpus import stopwords<br>stop_words = set(stopwords.words(‘english’))<br>tokens = [w for w in tokens if not w in stop_words]<br>print(tokens)</strong></span></pre><p id="7a5c" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">OUT: [‘The’, ‘quick’, ‘brown’, ‘fox’, ‘jumps’, ‘lazy’, ‘dog’]</p><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="9486" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph="">#NLTK provides several stemmer interfaces like Porter stemmer, #Lancaster Stemmer, Snowball Stemmer<br><strong class="oa gu">from nltk.stem.porter import PorterStemmer<br>porter = PorterStemmer()<br>stems = []<br>for t in tokens:    <br>    stems.append(porter.stem(t))<br>print(stems)</strong></span></pre><p id="7ddb" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">OUT: [‘the’, ‘quick’, ‘brown’, ‘fox’, ‘jump’, ‘lazi’, ‘dog’]</p><h2 id="d9b6" class="oe of gt be oy oz pa dx pb pc pd dz pe nh pf pg ph nl pi pj pk np pl pm pn po bj" data-selectable-paragraph="">Step 2: Feature Extraction</h2><p id="5ea7" class="pw-post-body-paragraph mw mx gt my b mz pp nb nc nd pq nf ng nh pr nj nk nl ps nn no np pt nr ns nt gm bj" data-selectable-paragraph="">In text processing, words of the text represent discrete, categorical features. How do we encode such data in a way which is ready to be used by the algorithms? The mapping from textual data to real valued vectors is called feature extraction. One of the simplest techniques to numerically represent text is <strong class="my gu">Bag of Words.</strong></p><p id="16fa" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph=""><strong class="my gu">Bag of Words (BOW):</strong> We make the list of unique words in the text corpus called vocabulary. Then we can represent each sentence or document as a vector with each word represented as 1 for present and 0 for absent from the vocabulary. Another representation can be count the number of times each word appears in a document. The most popular approach is using the <strong class="my gu">Term Frequency-Inverse Document Frequency (TF-IDF)</strong> technique.</p><ul class=""><li id="52a0" class="mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt pu pv pw bj" data-selectable-paragraph=""><strong class="my gu">Term Frequency (TF) </strong>= (Number of times term t appears in a document)/(Number of terms in the document)</li><li id="d4fb" class="mw mx gt my b mz px nb nc nd py nf ng nh pz nj nk nl qa nn no np qb nr ns nt pu pv pw bj" data-selectable-paragraph=""><strong class="my gu">Inverse Document Frequency (IDF) =</strong> log(N/n), where, N is the number of documents and n is the number of documents a term t has appeared in. The IDF of a rare word is high, whereas the IDF of a frequent word is likely to be low. Thus having the effect of highlighting words that are distinct.</li><li id="f7a7" class="mw mx gt my b mz px nb nc nd py nf ng nh pz nj nk nl qa nn no np qb nr ns nt pu pv pw bj" data-selectable-paragraph="">We calculate <strong class="my gu">TF-IDF</strong> value of a term as = TF * IDF</li></ul><p id="8989" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Let us take an example to calculate TF-IDF of a term in a document.</p><figure class="nu nv nw nx ny on ok ol paragraph-image"><div class="ok ol qc"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*S3jAdLlMm5w0AUXkhwSIzw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*S3jAdLlMm5w0AUXkhwSIzw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*S3jAdLlMm5w0AUXkhwSIzw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*S3jAdLlMm5w0AUXkhwSIzw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*S3jAdLlMm5w0AUXkhwSIzw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*S3jAdLlMm5w0AUXkhwSIzw.png 1100w, https://miro.medium.com/v2/resize:fit:848/format:webp/1*S3jAdLlMm5w0AUXkhwSIzw.png 848w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 424px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*S3jAdLlMm5w0AUXkhwSIzw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*S3jAdLlMm5w0AUXkhwSIzw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*S3jAdLlMm5w0AUXkhwSIzw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*S3jAdLlMm5w0AUXkhwSIzw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*S3jAdLlMm5w0AUXkhwSIzw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*S3jAdLlMm5w0AUXkhwSIzw.png 1100w, https://miro.medium.com/v2/resize:fit:848/1*S3jAdLlMm5w0AUXkhwSIzw.png 848w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 424px"><img alt="" class="bg md os c" width="424" height="219" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:636/1*S3jAdLlMm5w0AUXkhwSIzw.png"></picture></div><figcaption class="ot fe ou ok ol ov ow be b bf z dt" data-selectable-paragraph="">Example text corpus</figcaption></figure><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="ee67" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">TF('beautiful',Document1) = 2/10, IDF('beautiful')=log(2/2) = 0<br>TF(‘day’,Document1) = 5/10,  IDF(‘day’)=log(2/1) = 0.30<br><br>TF-IDF(‘beautiful’, Document1) = (2/10)*0 = 0<br>TF-IDF(‘day’, Document1) = (5/10)*0.30 = 0.15</strong></span></pre><p id="744c" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">As, you can see for Document1 , TF-IDF method heavily penalizes the word ‘beautiful’ but assigns greater weight to ‘day’. This is due to IDF part, which gives more weightage to the words that are distinct. In other words, ‘day’ is an important word for Document1 from the context of the entire corpus. Python <a class="af ox" href="http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html" rel="noopener ugc nofollow" target="_blank">scikit-learn</a> library provides efficient tools for text data mining and provides functions to calculate TF-IDF of text vocabulary given a text corpus.</p><p id="da50" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph=""><mark class="xt xu ao">One of the major disadvantages of using BOW is that it discards word order thereby ignoring the context and in turn meaning of words in the document.</mark> For natural language processing (NLP) maintaining the context of the words is of utmost importance. To solve this problem we use another approach called<strong class="my gu"> </strong>Word Embedding.</p><blockquote class="qd qe qf"><p id="9134" class="mw mx qg my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph=""><strong class="my gu">Word Embedding: </strong>It is a representation of text where words that have the same meaning have a similar representation. In other words it represents words in a coordinate system where related words, based on a corpus of relationships, are placed closer together.</p></blockquote><p id="474c" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Let us discuss some of the well known models of <em class="qg">word embedding</em>:</p><h2 id="ca54" class="oe of gt be oy oz pa dx pb pc pd dz pe nh pf pg ph nl pi pj pk np pl pm pn po bj" data-selectable-paragraph=""><strong class="al">Word2Vec</strong></h2><p id="e394" class="pw-post-body-paragraph mw mx gt my b mz pp nb nc nd pq nf ng nh pr nj nk nl ps nn no np pt nr ns nt gm bj" data-selectable-paragraph=""><a class="af ox" href="https://arxiv.org/abs/1301.3781" rel="noopener ugc nofollow" target="_blank">Word2vec </a>takes as its input a large corpus of text and produces a vector space with each unique word being assigned a corresponding vector in the space. Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space. Word2Vec is very famous at capturing meaning and demonstrating it on tasks like calculating analogy questions of the form <em class="qg">a</em> is to <em class="qg">b</em> as <em class="qg">c</em> is to <em class="qg">?</em>. For example, <em class="qg">man</em> is to <em class="qg">woman</em> as <em class="qg">uncle</em> is to <em class="qg">?</em> (<em class="qg">aunt</em>) using a simple vector offset method based on cosine distance. For example, here are vector offsets for three word pairs illustrating the gender relation:</p><figure class="nu nv nw nx ny on ok ol paragraph-image"><div class="ok ol qh"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*YG622JLh0bLaX4ushe4D2Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*YG622JLh0bLaX4ushe4D2Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*YG622JLh0bLaX4ushe4D2Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*YG622JLh0bLaX4ushe4D2Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*YG622JLh0bLaX4ushe4D2Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*YG622JLh0bLaX4ushe4D2Q.png 1100w, https://miro.medium.com/v2/resize:fit:524/format:webp/1*YG622JLh0bLaX4ushe4D2Q.png 524w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 262px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*YG622JLh0bLaX4ushe4D2Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*YG622JLh0bLaX4ushe4D2Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*YG622JLh0bLaX4ushe4D2Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*YG622JLh0bLaX4ushe4D2Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*YG622JLh0bLaX4ushe4D2Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*YG622JLh0bLaX4ushe4D2Q.png 1100w, https://miro.medium.com/v2/resize:fit:524/1*YG622JLh0bLaX4ushe4D2Q.png 524w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 262px"><img alt="" class="bg md os c" width="262" height="196" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:393/1*YG622JLh0bLaX4ushe4D2Q.png"></picture></div><figcaption class="ot fe ou ok ol ov ow be b bf z dt" data-selectable-paragraph="">vector offsets for gender relation</figcaption></figure><p id="6958" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">This kind of vector composition also lets us answer “King — Man + Woman = ?” question and arrive at the result “Queen” ! All of which is truly remarkable when you think that all of this knowledge simply comes from looking at lots of word in context with no other information provided about their semantics. For more details refer <a class="af ox" href="https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/" rel="noopener ugc nofollow" target="_blank">here</a>.</p><h2 id="a5d7" class="oe of gt be oy oz pa dx pb pc pd dz pe nh pf pg ph nl pi pj pk np pl pm pn po bj" data-selectable-paragraph=""><strong class="al">Glove</strong></h2><p id="281f" class="pw-post-body-paragraph mw mx gt my b mz pp nb nc nd pq nf ng nh pr nj nk nl ps nn no np pt nr ns nt gm bj" data-selectable-paragraph="">The Global Vectors for Word Representation, or <a class="af ox" href="http://doi.org/10.3115/v1/D14-1162" rel="noopener ugc nofollow" target="_blank">GloVe</a>, algorithm is an extension to the word2vec method for efficiently learning word vectors. GloVe constructs an explicit word-context or word co-occurrence matrix using statistics across the whole text corpus. The result is a learning model that may result in generally better word embeddings.</p><p id="203e" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Consider the following example:</p><figure class="nu nv nw nx ny on ok ol paragraph-image"><div role="button" tabindex="0" class="oo op fi oq bg or"><div class="ok ol qi"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 640w, https://miro.medium.com/v2/resize:fit:720/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 720w, https://miro.medium.com/v2/resize:fit:750/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 750w, https://miro.medium.com/v2/resize:fit:786/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 786w, https://miro.medium.com/v2/resize:fit:828/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg md os c" width="700" height="181" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:1050/1*dxuG0YGiwVloJ7fWPAx1ww@2x.png"></picture></div></div></figure><p id="4caa" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph=""><em class="qg">Target words:</em> ice, steam<br><em class="qg">Probe words:</em> solid, gas, water, fashion</p><p id="5216" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Let <em class="qg">P(k|w)</em> be the probability that the word <em class="qg">k</em> appears in the context of word <em class="qg">w</em>. Consider a word strongly related to <em class="qg">ice</em>, but not to <em class="qg">steam</em>, such as <em class="qg">solid</em>. <em class="qg">P(solid | ice)</em> will be relatively high, and <em class="qg">P(solid | steam)</em> will be relatively low. Thus the ratio of <em class="qg">P(solid | ice) / P(solid | steam)</em> will be large. If we take a word such as <em class="qg">gas</em> that is related to <em class="qg">steam</em> but not to <em class="qg">ice</em>, the ratio of <em class="qg">P(gas | ice) / P(gas | steam)</em> will instead be small. For a word related to both <em class="qg">ice</em> and <em class="qg">steam</em>, such as <em class="qg">water</em> we expect the ratio to be close to one. Refer <a class="af ox" href="https://blog.acolyer.org/2016/04/22/glove-global-vectors-for-word-representation/" rel="noopener ugc nofollow" target="_blank">here </a>for more details.</p><blockquote class="qd qe qf"><p id="c375" class="mw mx qg my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Word embeddings encode each word into a vector that captures some sort of relation and similarity between words within the text corpus. This means even the variations of words like case, spelling, punctuation, and so on will be automatically learned. In turn, this can mean that some of the text cleaning steps described above may no longer be required.</p></blockquote><h2 id="774c" class="oe of gt be oy oz pa dx pb pc pd dz pe nh pf pg ph nl pi pj pk np pl pm pn po bj" data-selectable-paragraph="">Step 3: Choosing ML Algorithms</h2><p id="6332" class="pw-post-body-paragraph mw mx gt my b mz pp nb nc nd pq nf ng nh pr nj nk nl ps nn no np pt nr ns nt gm bj" data-selectable-paragraph="">There are various approaches to building ML models for various text based applications depending on what is the problem space and data available.</p><p id="9e6f" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Classical ML approaches like ‘Naive Bayes’ or ‘Support Vector Machines’ for spam filtering has been widely used. Deep learning techniques are giving better results for NLP problems like sentiment analysis and language translation. Deep learning models are very slow to train and it has been seen that for simple text classification problems classical ML approaches as well give similar results with quicker training time.</p><p id="34fd" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Let us build a <strong class="my gu">Sentiment Analyzer</strong> over the <a class="af ox" href="http://ai.stanford.edu/~amaas/data/sentiment/" rel="noopener ugc nofollow" target="_blank">IMDB </a>movie review dataset using the techniques discussed so far.</p><h2 id="be4a" class="oe of gt be oy oz pa dx pb pc pd dz pe nh pf pg ph nl pi pj pk np pl pm pn po bj" data-selectable-paragraph="">Download the IMDb Movie Review Data</h2><p id="db5f" class="pw-post-body-paragraph mw mx gt my b mz pp nb nc nd pq nf ng nh pr nj nk nl ps nn no np pt nr ns nt gm bj" data-selectable-paragraph="">The IMDB movie review set can be downloaded from <a class="af ox" href="http://ai.stanford.edu/~amaas/data/sentiment/" rel="noopener ugc nofollow" target="_blank">here</a>. This dataset for binary sentiment classification contains set of 25,000 highly polar movie reviews for training, and 25,000 for testing. This dataset was used for the very popular paper <a class="af ox" href="http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf" rel="noopener ugc nofollow" target="_blank">‘Learning Word Vectors for Sentiment Analysis’</a>.</p><h2 id="7489" class="oe of gt be oy oz pa dx pb pc pd dz pe nh pf pg ph nl pi pj pk np pl pm pn po bj" data-selectable-paragraph="">Preprocessing</h2><p id="f377" class="pw-post-body-paragraph mw mx gt my b mz pp nb nc nd pq nf ng nh pr nj nk nl ps nn no np pt nr ns nt gm bj" data-selectable-paragraph="">The dataset is structured as test set and training set of 25000 files each. Let us first read the files into a python dataframe for further processing and visualization. The test and training set are further divided into 12500 ‘positive’ and ‘negative’ reviews each. We read each file and label negative review as ‘0’ and positive review as ‘1’</p><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="74e3" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph="">#convert the dataset from files to a python DataFrame</span><span id="4572" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">import pandas as pd<br>import os</strong></span><span id="38cb" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">folder = 'aclImdb'</strong></span><span id="be0f" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">labels = {'pos': 1, 'neg': 0}</strong></span><span id="f56d" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">df = pd.DataFrame()</strong></span><span id="76f5" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">for f in ('test', 'train'):    <br>    for l in ('pos', 'neg'):<br>        path = os.path.join(folder, f, l)<br>        for file in os.listdir (path) :<br>            with open(os.path.join(path, file),'r', encoding='utf-8') as infile:<br>                txt = infile.read()<br>            df = df.append([[txt, labels[l]]],ignore_index=True)</strong></span><span id="6bed" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">df.columns = ['review', 'sentiment']</strong></span></pre><p id="3d34" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Let us save the assembled data as .csv file for further use.</p><figure class="nu nv nw nx ny on ok ol paragraph-image"><div class="ok ol qj"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*IIIRW2kWF5a7qGjZObiJ3Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*IIIRW2kWF5a7qGjZObiJ3Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*IIIRW2kWF5a7qGjZObiJ3Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*IIIRW2kWF5a7qGjZObiJ3Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*IIIRW2kWF5a7qGjZObiJ3Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*IIIRW2kWF5a7qGjZObiJ3Q.png 1100w, https://miro.medium.com/v2/resize:fit:1030/format:webp/1*IIIRW2kWF5a7qGjZObiJ3Q.png 1030w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 515px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*IIIRW2kWF5a7qGjZObiJ3Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*IIIRW2kWF5a7qGjZObiJ3Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*IIIRW2kWF5a7qGjZObiJ3Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*IIIRW2kWF5a7qGjZObiJ3Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*IIIRW2kWF5a7qGjZObiJ3Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*IIIRW2kWF5a7qGjZObiJ3Q.png 1100w, https://miro.medium.com/v2/resize:fit:1030/1*IIIRW2kWF5a7qGjZObiJ3Q.png 1030w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 515px"><img alt="" class="bg md os c" width="515" height="296" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:773/1*IIIRW2kWF5a7qGjZObiJ3Q.png"></picture></div><figcaption class="ot fe ou ok ol ov ow be b bf z dt" data-selectable-paragraph="">Five reviews and the corresponding sentiment</figcaption></figure><p id="9fb4" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">To get the frequency distribution of the words in the text, we can utilize the <code class="cw qk ql qm oa b">nltk.FreqDist()</code> function, which lists the top words used in the text, providing a rough idea of the main topic in the text data, as shown in the following code:</p><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="6bb3" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">import nltk<br>from nltk.tokenize import word_tokenize</strong></span><span id="a872" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">reviews = df.review.str.cat(sep=' ')</strong></span><span id="d80c" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">#function to split text into word<br>tokens = word_tokenize(reviews)</strong></span><span id="9307" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">vocabulary = set(tokens)<br>print(len(vocabulary))</strong></span><span id="36c7" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">frequency_dist = nltk.FreqDist(tokens)<br>sorted(frequency_dist,key=frequency_dist.__getitem__, reverse=True)[0:50]</strong></span></pre><p id="1fe0" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">This gives the top 50 words used in the text, though it is obvious that some of the stop words, such as <code class="cw qk ql qm oa b">the</code>, frequently occur in the English language.</p><figure class="nu nv nw nx ny on ok ol paragraph-image"><div role="button" tabindex="0" class="oo op fi oq bg or"><div class="ok ol qn"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*YLmyQRtNroTvNiOBAOZQeg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*YLmyQRtNroTvNiOBAOZQeg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*YLmyQRtNroTvNiOBAOZQeg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*YLmyQRtNroTvNiOBAOZQeg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*YLmyQRtNroTvNiOBAOZQeg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*YLmyQRtNroTvNiOBAOZQeg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YLmyQRtNroTvNiOBAOZQeg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*YLmyQRtNroTvNiOBAOZQeg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*YLmyQRtNroTvNiOBAOZQeg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*YLmyQRtNroTvNiOBAOZQeg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*YLmyQRtNroTvNiOBAOZQeg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*YLmyQRtNroTvNiOBAOZQeg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*YLmyQRtNroTvNiOBAOZQeg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*YLmyQRtNroTvNiOBAOZQeg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg md os c" width="700" height="52" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:1050/1*YLmyQRtNroTvNiOBAOZQeg.png"></picture></div></div><figcaption class="ot fe ou ok ol ov ow be b bf z dt" data-selectable-paragraph="">Top 50 words</figcaption></figure><p id="36b1" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Look closely and you find lot of unnecessary punctuation and tags. By excluding single and two letter words the stop words like <code class="cw qk ql qm oa b">the</code>, <code class="cw qk ql qm oa b">this</code>, <code class="cw qk ql qm oa b">and</code>, <code class="cw qk ql qm oa b">that</code> take the top slot in the word frequency distribution plot shown below.</p><figure class="nu nv nw nx ny on ok ol paragraph-image"><div class="ok ol qo"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*8Gnd17LJBux4fLz1uiJzXQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*8Gnd17LJBux4fLz1uiJzXQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*8Gnd17LJBux4fLz1uiJzXQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*8Gnd17LJBux4fLz1uiJzXQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*8Gnd17LJBux4fLz1uiJzXQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*8Gnd17LJBux4fLz1uiJzXQ.png 1100w, https://miro.medium.com/v2/resize:fit:924/format:webp/1*8Gnd17LJBux4fLz1uiJzXQ.png 924w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 462px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*8Gnd17LJBux4fLz1uiJzXQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*8Gnd17LJBux4fLz1uiJzXQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*8Gnd17LJBux4fLz1uiJzXQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*8Gnd17LJBux4fLz1uiJzXQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*8Gnd17LJBux4fLz1uiJzXQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*8Gnd17LJBux4fLz1uiJzXQ.png 1100w, https://miro.medium.com/v2/resize:fit:924/1*8Gnd17LJBux4fLz1uiJzXQ.png 924w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 462px"><img alt="" class="bg md os c" width="462" height="323" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:693/1*8Gnd17LJBux4fLz1uiJzXQ.png"></picture></div></figure><p id="8f77" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Let us remove the stop words to further cleanup the text corpus.</p><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="50b1" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">from nltk.corpus import stopwords</strong></span><span id="8ea8" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">stop_words = set(stopwords.words('english'))<br>tokens = [w for w in tokens if not w in stop_words]</strong></span></pre><figure class="nu nv nw nx ny on ok ol paragraph-image"><div role="button" tabindex="0" class="oo op fi oq bg or"><div class="ok ol qp"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*0O-nozZ2csh8doqiGEZhlQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*0O-nozZ2csh8doqiGEZhlQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*0O-nozZ2csh8doqiGEZhlQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*0O-nozZ2csh8doqiGEZhlQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*0O-nozZ2csh8doqiGEZhlQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*0O-nozZ2csh8doqiGEZhlQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0O-nozZ2csh8doqiGEZhlQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*0O-nozZ2csh8doqiGEZhlQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*0O-nozZ2csh8doqiGEZhlQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*0O-nozZ2csh8doqiGEZhlQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*0O-nozZ2csh8doqiGEZhlQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*0O-nozZ2csh8doqiGEZhlQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*0O-nozZ2csh8doqiGEZhlQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*0O-nozZ2csh8doqiGEZhlQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg md os c" width="700" height="59" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:1050/1*0O-nozZ2csh8doqiGEZhlQ.png"></picture></div></div><figcaption class="ot fe ou ok ol ov ow be b bf z dt" data-selectable-paragraph="">Top 50 words</figcaption></figure><p id="b9a8" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">This looks like a cleaned text corpus now and words like <code class="cw qk ql qm oa b">went</code>, <code class="cw qk ql qm oa b">saw</code>, <code class="cw qk ql qm oa b">movie </code>etc. taking the top slots as expected.</p><p id="096c" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Another helpful visualization tool <code class="cw qk ql qm oa b">wordcloud</code> package helps to create word clouds by placing words on a canvas randomly, with sizes proportional to their frequency in the text.</p><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="0143" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">from wordcloud import WordCloud<br>import matplotlib.pyplot as plt</strong></span><span id="0ba5" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">wordcloud = WordCloud().<br>generate_from_frequencies(frequency_dist)</strong></span><span id="4793" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">plt.imshow(wordcloud)<br>plt.axis("off")<br>plt.show()</strong></span></pre><figure class="nu nv nw nx ny on ok ol paragraph-image"><div class="ok ol qq"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*xHKuQdJrg24oMfad8PyyKg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*xHKuQdJrg24oMfad8PyyKg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*xHKuQdJrg24oMfad8PyyKg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*xHKuQdJrg24oMfad8PyyKg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*xHKuQdJrg24oMfad8PyyKg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*xHKuQdJrg24oMfad8PyyKg.png 1100w, https://miro.medium.com/v2/resize:fit:1282/format:webp/1*xHKuQdJrg24oMfad8PyyKg.png 1282w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 641px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*xHKuQdJrg24oMfad8PyyKg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*xHKuQdJrg24oMfad8PyyKg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*xHKuQdJrg24oMfad8PyyKg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*xHKuQdJrg24oMfad8PyyKg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*xHKuQdJrg24oMfad8PyyKg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*xHKuQdJrg24oMfad8PyyKg.png 1100w, https://miro.medium.com/v2/resize:fit:1282/1*xHKuQdJrg24oMfad8PyyKg.png 1282w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 641px"><img alt="" class="bg md os c" width="641" height="323" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:962/1*xHKuQdJrg24oMfad8PyyKg.png"></picture></div></figure><h2 id="11b2" class="oe of gt be oy oz pa dx pb pc pd dz pe nh pf pg ph nl pi pj pk np pl pm pn po bj" data-selectable-paragraph="">Building a Classifier</h2><p id="1407" class="pw-post-body-paragraph mw mx gt my b mz pp nb nc nd pq nf ng nh pr nj nk nl ps nn no np pt nr ns nt gm bj" data-selectable-paragraph="">After cleanup, it is time to build the classifier to identify sentiment of each movie review. From the IMDb dataset, divide test and training sets of 25000 each:</p><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="1f65" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph="">X_train = df.loc[:24999, 'review'].values<br>y_train = df.loc[:24999, 'sentiment'].values<br>X_test = df.loc[25000:, 'review'].values<br>y_test = df.loc[25000:, 'sentiment'].values</span></pre><p id="9e76" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph=""><code class="cw qk ql qm oa b"><strong class="my gu">scikit-learn</strong></code> provides some cool tools to do pre-processing on text. We use <code class="cw qk ql qm oa b">TfidTransformer</code> to covert the text corpus into the feature vectors, we restrict the maximum features to 10000. For further details about how to use<code class="cw qk ql qm oa b">TfidTransformer</code>refer <a class="af ox" href="http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html" rel="noopener ugc nofollow" target="_blank">here</a>.</p><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="99e9" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">from sklearn.feature_extraction.text import TfidfTransformer<br>from sklearn.feature_extraction.text import TfidfVectorizer</strong></span><span id="a67a" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">vectorizer = TfidfVectorizer()<br>train_vectors = vectorizer.fit_transform(X_train)<br>test_vectors = vectorizer.transform(X_test)<br>print(train_vectors.shape, test_vectors.shape)</strong></span></pre><figure class="nu nv nw nx ny on ok ol paragraph-image"><div class="ok ol qr"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*9gGscyg7dKpjabT78TUqRQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*9gGscyg7dKpjabT78TUqRQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*9gGscyg7dKpjabT78TUqRQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*9gGscyg7dKpjabT78TUqRQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*9gGscyg7dKpjabT78TUqRQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*9gGscyg7dKpjabT78TUqRQ.png 1100w, https://miro.medium.com/v2/resize:fit:696/format:webp/1*9gGscyg7dKpjabT78TUqRQ.png 696w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 348px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*9gGscyg7dKpjabT78TUqRQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*9gGscyg7dKpjabT78TUqRQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*9gGscyg7dKpjabT78TUqRQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*9gGscyg7dKpjabT78TUqRQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*9gGscyg7dKpjabT78TUqRQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*9gGscyg7dKpjabT78TUqRQ.png 1100w, https://miro.medium.com/v2/resize:fit:696/1*9gGscyg7dKpjabT78TUqRQ.png 696w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 348px"><img alt="" class="bg md os c" width="348" height="40" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:522/1*9gGscyg7dKpjabT78TUqRQ.png"></picture></div><figcaption class="ot fe ou ok ol ov ow be b bf z dt" data-selectable-paragraph="">Training and Test set: 25K with 10K Features</figcaption></figure><p id="ada3" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">There are many algorithms to choose from, we will use a basic Naive Bayes Classifier and train the model on the training set.</p><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="c5e7" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">from sklearn.naive_bayes import MultinomialNB</strong></span><span id="e919" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">clf = MultinomialNB().fit(train_vectors, y_train)</strong></span></pre><p id="f25a" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Our Sentiment Analyzer is ready and trained. Now let us test the performance of our model on the test set to predict the sentiment labels.</p><pre class="nu nv nw nx ny nz oa ob oc ax od bj"><span id="ca72" class="oe of gt oa b in og oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">from  sklearn.metrics  import accuracy_score</strong></span><span id="f104" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">predicted = clf.predict(test_vectors)</strong></span><span id="d34c" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu">print(accuracy_score(y_test,predicted))</strong></span><span id="effd" class="oe of gt oa b in oj oh l jc oi" data-selectable-paragraph=""><strong class="oa gu"><em class="qg">Output 0.791</em></strong></span></pre><p id="ef7a" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Wow!!! Basic NB classifier based Sentiment Analyzer does well to give around 79% accuracy. You can try changing features vector length and varying parameters of<code class="cw qk ql qm oa b">TfidTransformer</code>to see the impact on the accuracy of the model.</p><p id="863c" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph=""><strong class="my gu">Conclusion: </strong>We have discussed the text processing techniques used in NLP in detail. We also demonstrated the use of text processing and build a Sentiment Analyzer with classical ML approach achieved fairly good results.</p><p id="4b69" class="pw-post-body-paragraph mw mx gt my b mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr ns nt gm bj" data-selectable-paragraph="">Thanks for reading this article, recommend and share if you like it.</p><h2 id="060e" class="oe of gt be oy oz pa dx pb pc pd dz pe nh pf pg ph nl pi pj pk np pl pm pn po bj" data-selectable-paragraph="">Further Reading:</h2><div class="qs qt qu qv qw qx"><a href="https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/?source=post_page-----1d5a2d638958--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qy ab iw"><div class="qz ab cn ca ra rb"><h2 class="be gu in z je rc jg jh rd jj jl gs bj">An Intuitive Understanding of Word Embeddings: From Count Vectors to Word2Vec</h2><div class="re l"><h3 class="be b in z je rc jg jh rd jj jl dt">Introduction Before we start, have a look at the below examples. You open Google and search for a news article on the…</h3></div><div class="rf l"><p class="be b du z je rc jg jh rd jj jl dt">www.analyticsvidhya.com</p></div></div><div class="rg l"><div class="rh l ri rj rk rg rl md qx"></div></div></div></a></div><div class="qs qt qu qv qw qx"><a href="https://machinelearningmastery.com/what-are-word-embeddings/?source=post_page-----1d5a2d638958--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="qy ab iw"><div class="qz ab cn ca ra rb"><h2 class="be gu in z je rc jg jh rd jj jl gs bj">What Are Word Embeddings for Text?</h2><div class="re l"><h3 class="be b in z je rc jg jh rd jj jl dt">Word embeddings are a type of word representation that allows words with similar meaning to have a similar…</h3></div><div class="rf l"><p class="be b du z je rc jg jh rd jj jl dt">machinelearningmastery.com</p></div></div><div class="rg l"><div class="rm l ri rj rk rg rl md qx"></div></div></div></a></div></div>
</body>
</html>